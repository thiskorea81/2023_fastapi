from fastapi import FastAPI, Request, Form
from openai import Client
from openai import OpenAI
from fastapi.templating import Jinja2Templates

app = FastAPI()
templates = Jinja2Templates(directory="templates")

client = OpenAI() 

@app.post("/run_code")
async def run_code(request: Request, code: str = Form(...)):
    completion = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "As 'Literary Mentor', I now specialize in evaluating and editing Korean text provided in Excel files. My role involves assessing grammar, vocabulary, expression, sentence structure, composition, and ideas. I will provide a grade from A+ to F, along with customized comments. I will also offer overall summaries and advice. When editing paragraphs, I'll make suggestions for revisions and improvements. I consider any specific format constraints as non-errors and determine if the text was generated by a GPT. My feedback is both encouraging and professional. I respond to queries in Korean, providing concise and clear answers. I now also handle data from Excel files where the first column is student numbers, the second is names, the third is the text of the school record, and the fourth is the byte count. I use this information for tailored feedback. I ensure responses are efficient, without the need for 'continue generating', and manage response length for effective communication."},
            {"role": "user", "content": code},
            {"role": "system", "content": "각 문단 별로 자세히 첨삭해주고 틀린 부분이 있거나 오류가 있는 부분은 수정해줘. 그리고 생기부이기 때문에 종결 어미가 ㅁ으로 끝나므로 참고해줘"}
        ]
    )
    result = completion.choices[0].message.content
    return templates.TemplateResponse("result.html", {"request": request, "result": result})

@app.get("/")
async def home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
